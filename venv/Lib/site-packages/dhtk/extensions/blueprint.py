"""Abstract class to be used as template for new extension modules __init__ script"""

# Import dependencies
import abc
from dhtk.core.system import download_files
import typing
import docker
import time
import tqdm
import re
import subprocess
import sys
import warnings
import SPARQLWrapper
import platform

warnings.formatwarning = lambda message, *args: f"{message}\n"


class AbstractExtension(abc.ABC):
    """Abstract Class that serves as a blueprint for the DHTK extension modules
    and additional datasets. All new extensions inheriting from this class must define:

    Attributes
    ----------
    name: string
        Name of the DHTK extension
    url: string
        URL to the DHTK extension RDF file to be downloaded

    Methods
    -------
    get: A method unifying the main extension queries.
    save: A method to download and store the queried information
    welcome: An optional method to display a message after extension is loaded
    """

    def __init__(self, settings, client):
        """Instantiation of Triplestore object.

        Parameters
        ----------
        settings: DHTK Settings object
            Configurations to use
        client: DHTK Client object
            Client to use
        """
        # Defaults required to be defined for each extension
        self.name = ""  # Must be defined for Extension
        self.url = ""  # Must be defined for Extension

        # Set up DHTK setting
        self.CONFIGS = settings
        self.CLIENT = client
        self.wd = settings.wd
        self.port = settings.port
        self.ENDPOINT = self.CLIENT.client
        self.LOGS = settings.logger

        # Log call
        self.LOGS.debug(f"EXTENSION: Extension module {self.name} was instantiated")

        # Start Fuseki app
        if not isinstance(self.ENDPOINT, str):
            self.CLIENT.client.containers.get("dhtk-app").start()

    def _check_endpoint(self) -> None:
        """Method to replace the local endpoint with the correct value"""
        # Log call
        self.LOGS.debug(f"EXTENSION ({self.name}): AbstractExtension._check_endpoint method was called")

        if not isinstance(self.ENDPOINT, str): # local endpoints are docker connections
            endpoint = f"http://localhost:{self.port}/" + self.name + "/sparql"

            self.ENDPOINT = endpoint

            self.LOGS.info(f"EXTENSION ({self.name}): Local endpoint was updated to {endpoint}")

    def delete(self):
        """Method to fully clear the existing data on the local endopoint"""
        # Replace Fuseki GET with UPDATE URL
        update = re.sub("query", "update", self.ENDPOINT)
        update = re.sub("sparql", "update", update)

        # UPDATE query
        sparql = SPARQLWrapper.SPARQLWrapper(update)
        sparql.setCredentials(user="admin", passwd="pw123")
        sparql.setMethod(SPARQLWrapper.POST)
        sparql.setQuery("CLEAR DEFAULT")
        sparql.query()

    # Methods to set up locally
    def set_up(self) -> None:
        """Method to retrieve the DHTK extension dataset stored remotely (on Zenodo) and
        upload it to the local Fuseki server"""
        # Log call
        self.LOGS.debug(f"(EXTENSION ({self.name}): AbstractExtension.set_up() method was called")

        # Set up and upload
        file = self._download_metadata()
        self._fuseki_upload(file)

        # Restart Fuseki app
        print("Restarting Fuseki endpoint")
        self.CLIENT.client.containers.get("dhtk-app").restart()
        time.sleep(10)

    def _download_metadata(self) -> str:
        """Method to download the data using the extension URL attribute

        Returns
        -------
        Path to the downloaded RDF file containing the triples
        """
        # Log call
        self.LOGS.debug(f"(EXTENSION ({self.name}): AbstractExtension._download_metadata() method was called")

        file = download_files(urls=self.url, name=f"Downloading {self.name}")  # core.system.py

        return file

    def _fuseki_upload(self, rdf: str, desc="Uploading metadata to local server") -> None:
        """Method to upload an RDF file to local Fuseki client

        Parameters
        ----------
        rdf: string
            Path to the RDF file to be uploaded
        desc: string:
            Description for progress bar to show during upload
        """
        # Log call
        self.LOGS.debug(f"(EXTENSION ({self.name}): Triplestore._fuseki_upload(rdf={rdf}) method was called")

        # Should only be used for local endppints
        if isinstance(self.CLIENT.client, str):
            warnings.warn("Please don't call TripleStore.set_up if you're using remote triplestore")
            self.LOGS.error(f"(EXTENSION ({self.name}): _fuseki_upload(rdf={rdf}) failed because the client is remote!")

            return None

        # Get endpoint information
        available = self.CLIENT.get_objects("containers")
        available = [container.name for container in available["containers"]]  # Remove empty containers
        fuseki_load = self._prepare_upload(rdf)
        client = self.CLIENT.client

        # Close container if running and restart it
        if fuseki_load["name"] in available:
            client.containers.get(fuseki_load["name"]).stop()
            client.containers.get(fuseki_load["name"]).remove()

        # Load file to volume
        client.containers.run(
            name=fuseki_load["name"],
            image=fuseki_load["image"],
            volumes_from=fuseki_load["volumes_from"],
            volumes=fuseki_load["volumes"],
            command=['./load.sh', self.name, fuseki_load["file"]],
            detach=fuseki_load["detach"]
        )

        # Check progress
        bar, total, completed = self._progress_bar(rdf, desc)
        self.LOGS.info("Uploading triples to local Fuseki")

        while True:
            # Check docker container's logs for finished upload
            update = self._upload_check(client=client, volume=fuseki_load["name"])

            if isinstance(update, list):
                bar, completed = self._update_progress(bar, update, completed)
            elif not update:
                break

        bar.close()

        self.LOGS.info(f"Upload complete. Closing volume and removing {rdf}")

        # Stop container and remove file from system
        print("Cleaning Fuseki loader")
        client.containers.get(fuseki_load["name"]).stop()
        client.containers.get(fuseki_load["name"]).remove()
        os = platform.system()
        if os != "Windows":
            subprocess.check_call(["rm", rdf])
        else:
            subprocess.check_call(f'del {rdf}', shell=True)

    # Upload helper methods
    def _prepare_upload(self, rdf: str) -> dict:
        """Method to prepare the instruction to upload the RDF file to Fuseki

        Parameters
        ----------
        rdf: string
            Path to the RDF file to be uploaded

        Returns
        -------
        Fuseki load.sh script
        """
        # Log call
        self.LOGS.debug(f"(EXTENSION ({self.name}): Triplestore._prepare_upload(rdf={rdf}) method was called")

        fuseki_load = {"name": 'fuseki-load',
                       "image": 'myclassunil/jena-fuseki:latest',
                       "volumes_from": 'dhtk-data',
                       "volumes": {self.wd: {'bind': '/staging'}},
                       "detach": True,
                       "file": rdf}

        return fuseki_load

    def _upload_check(self, client: docker.DockerClient, volume: str) -> typing.Union[bool, typing.List]:
        """
        Method to retrieve, check and evaluate the Docker logs during upload

        Parameters
        ----------
        client: docker.DockerClient
            Connection to local Fuseki server
        volume: string
            Name of volume where the triples are being uploaded

        Returns
        -------
        The return value depends on the upload progress.
        If ending logs are found, return False, otherwise return True or equivalent information object.

        Information object contain the stage of upload (add/slot) and the number of triples already completed
        """
        # Retrieve Docker logs from volume
        c = client.containers.get(volume)
        log = c.logs()
        log = str(log)
        log = log.split("\\n")
        log = " ".join(log[-5:])

        # Check if upload has finished.
        if "Finish quads load" in log:
            return False
        if "No files found for" in log:
            return False
        if "ERROR" in log or "at tdb.tdbloader.main" in log:
            print("Error uploading")
            self.LOGS.error("DOCKER: Error uploading")
            sys.exit()

        # Slotting logs
        if "INFO  Index SPO->POS:" in log:
            completed = re.sub("\n", "", log)
            completed = re.sub(".*INFO\\s*Index SPO->POS: ([0-9,]*) slots.*", "\\1", completed)
            completed = re.sub(",", "", completed)
            completed = int(completed)

            return ["slot", completed]

        # Adding logs
        elif "INFO  Add:" in log:
            completed = re.sub(".*INFO\\s*Add: ([0-9,]*) triples.*", "\\1", log)
            completed = re.sub(",", "", completed)
            completed = int(completed)

            return ["add", completed]

        return True

    @staticmethod
    def _progress_bar(rdf: str, desc: str) -> tuple:
        """Method to generate the upload progress bar

        Parameters
        ----------
        rdf: string
            Name of the RDF file to upload to Fuseki
        desc: string:
            Description for progress bar to show during upload

        Returns
        -------
        A tqdm progress bar object, the estimated total number of triples and the current progress
        """
        total = 0
        rdf = open(str(rdf), encoding='utf8')
        # Estimate file size (not quite right)
        for line in rdf:
            total += line.count(" ;")
            total += line.count(" ,")
            total += line.count(" .")

        # Create progress bar
        desc = re.sub("Uploading", "Uploading (add)", desc)
        progress = tqdm.tqdm(desc=desc, total=total)

        return progress, total, 0

    @staticmethod
    def _update_progress(bar: tqdm.std.tqdm, update: typing.List, tracker: int) -> tuple:
        """Method to update upload progress bar

        Parameters
        ----------
        bar: tqdm.std.tqdm
            A progress bar
        tracker: integer
            Number of triples uploaded or slotted to Fuseki
        update:
            Evaluation of Docker logs

        Returns
        -------
        An updated tqdm progress bar object (and number of completed triples)
        """
        # Refresh progress bar
        bar.n = tracker
        bar.refresh()

        # Uploading happens in two stages: add triples and slot them.
        # Set up two progress bars to reflect the two uploade stages.
        if update[0] == "add":
            tracker = update[1]
        elif update[0] == "slot":
            if "add" in bar.desc:
                bar.close()
                desc = re.sub("add", "slot", bar.desc)
                bar = tqdm.tqdm(desc=desc, total=tracker)
            tracker = update[1]

        return bar, tracker

    # Quitting methods
    def close(self):
        self.CLIENT.client.containers.get("dhtk-app").stop()
        msg = "\n".join(["##########################",
                         "Thank you for using DHTK!",
                         "##########################",
                         "Please send them any comments or suggestions to davide.picca@unil.ch.",
                         "Use exit() when you're done",
                         ])
        print(msg)

    # Extension implementation
    @abc.abstractmethod
    def get(self, what, name, add):
        pass

    @abc.abstractmethod
    def welcome(self):
        pass

    @abc.abstractmethod
    def save(self):
        pass
