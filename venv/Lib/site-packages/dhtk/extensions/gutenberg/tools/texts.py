

"""
Contains GutenbergTexts Class.


Notes
-----
This class is being reworked.
The cleaning of the texts was adapted from: https://github.com/okfn/gutenizer
"""

from pathlib import Path
import re
import shutil
from tempfile import mkdtemp
import pathlib
import zipfile
import chardet

from dhtk.core.system import download_files, url_exists


class GutenbergTexts:
    r"""
    Clean up Gutenberg texts by removing all the header and footer bumpf.

    Notes
    -----
    Part of this class have to be reworked.

    Usage: init and then run _extract_text.
    """

    # TODO: deal with 'Produced by ' which occurs in both header and footer (and
    #    so cannot be dealt with by the usual methods).

    # TODO: Could probably be improved by:
    #    https://raw.githubusercontent.com/c-w/gutenberg/master/gutenberg/_domain_model/text.py

    # TODO: Regex for formatting:
    #    part tiles:
    #        r"((?:(?:PART)|(?:Part))[ ][IVLX]+)[:.\s]"
    #    book titles:
    #        r"((?:(?:BOOK)|(?:Book))[ ][IVLX]+)[:.\s]"
    #    chapter titles:
    #        r"((?:(?:CHAPTER)|(?:Chapter))[ ][IVLX]+)[:.\s]+([\s\S+]*?\s{2})"

    # TODO: chapter separation :
    #    Suggestion 1 (need to add a list of verbs in the negative lookahead parenthesis):
    #    r"(?<!\w| |,|\.|:|;|!|\?)((?:(?:CHAPTER)|(?:Chapter)|(?:Scene)|(?:SCENE))?[ ]?" \
    #    r"[IVLX1234567890]+[-:窶能.\s]+?)(?=[\s\S+]*?\n{2})(?!(was|have|am|will|do))"
    #    Suggestion 1 (Compact):
    #    r"(?<![\w ,\.:;!\?])((?:(?:CHAPTER)|(?:Chapter)|(?:Scene)|(?:SCENE))?[ ]?[IVLX0-9]+" \
    #    r"[-:窶能.\s]+?)(?=[\s\S+]*?\n{2})(?!(was|have|am|will|do))"
    #   Suggestion 2:
    #    r"(?<!\w|[ ]|,|\.|:|;|!|\?)((?:(?:CHAPTER)|(?:Chapter)|(?:Scene)|(?:SCENE))?[ ]?" \
    #    r"[IVLX1234567890]+[-:窶能.\s]+?)(?=[\s\S+]*?\n{2})(?<! )(.+)"
    #    Suggestion 2 (compact):
    #    r"(?<![\w ,\.:;!\?])((?:(?:CHAPTER)|(?:Chapter)|(?:Scene)|(?:SCENE))?[ ]?[IVLX0-9]+" \
    #    r"[-:窶能.\s]+?)(?=[\s\S+]*?\n{2})(?<! )(.+)"
    #    Suggestion 3:
    #    r"^[\n\r]{2,}[     ]*(((?:(?:(CHAPTER|Chapter)[ ]?))?[IVXL\d]+[.: ]?" \
    #    r"[\n\r]*?.+)|([A-Z]+[A-Z '"-.,;:]*[A-Z:]))[\n\r]{2,}(?!(CHAPTER|Chapter))\w+"

    #TODO: Footnotes:
    #    In-text footnotes:
    #    r"(\[(?:(?:FOOTNOTE)|(?:Footnote)|(?:footnote)|(?:FOOTNOTES)|(?:Footnotes)|" \
    #    r"(?:footnotes))[-:\.\n]+.+\])"
    #    End of text footnotes (add re.MULTILINE so that "^"
    #    will be considered as beginning of line, (re.compile(r"my_regex", re.MULTILINE))):
    #    r"(^(?:(?:FOOTNOTE)|(?:Footnote)|(?:footnote)|(?:FOOTNOTES)|(?:Footnotes)|" \
    #    r"(?:footnotes))(?:\s.*)+?)(?=\s\*)"

    #TODO: Parts:
    #    Suggestion 1: r"((?:(?:PART)|(?:Part)|(?:part)|(?:ACT)|(?:Act)|(?:act))\s+[IVLX]+)[:.\s]"

# TODO: review below (not pare of core)

    _notes_end = ""
    _header_end = ""
    _footer_start = ""
    _original_text = ""
    _clean_text = ""
    _url = ""


    header_end_phrases = [
        "Project Gutenberg's Etext of",
        'This gutenberg_book was prepared by',
        'THE SMALL PRINT',
        'START OF THIS PROJECT GUTENBERG',
        'START OF THE PROJECT GUTENBERG EBOOK',
        'START OF THIS PROJECT GUTENBERG EBOOK',
    ]
    notes_start_phrases = ["Executive Director's Notes:"]
    notes_end_phrases = ['David Reed']
    footer_start_phrases = [
        'End of Project Gutenberg',
        'END OF THE PROJECT GUTENBERG EBOOK',
        'End of The Project Gutenberg',
        'END OF THIS PROJECT GUTENBERG EBOOK',
        'End of the Project Gutenberg EBook of',
    ]

    def __init__(self, book, repository_uri='http://aleph.gutenberg.org'):
        """
        Init function of the GutenbergTexts.

        Check repository_uri and create a temporary directory for file operations.
        repository_uri: can be local file:/path/to/dir
        refer to:
        https://www.gutenberg.org/wiki/Gutenberg:Information_About_Robot_Access_to_our_Pages
        to download the files.

        Parameters
        ------------------
        repository_uri: str
            Can be a file uri file://home/user/Documents/gutenberg_dump or
            an http uri: http://aleph.gutenberg.org
        """
        if not repository_uri:
            raise ValueError("Please set the URI of a 'local' gutenberg text repository.")

        if "http://www.gutenberg.org/files" in repository_uri:
            raise ValueError(
                """
                Please create a local repository. More information on:
                https://www.gutenberg.org/wiki/Gutenberg:Information_About_Robot_Access_to_our_Pages
                """
            )

        self._temporary_dir = Path(mkdtemp(prefix="dhtk-"))
        self._repository_uri = repository_uri
        self.book = book

    def get_original_text(self):
        """
        Returns original text of a given book.


        Parameters
        ----------
        book: dhtk.common.book.Book
            An instance of class Book in dhtk.common.book

        Returns
        -------
        return: str:
            Text of the book as formatted in http://aleph.gutenberg.org/1/3/0/0/13000/13000.txt
        """
        found_url = False
        url = ""
        if self._original_text:
            return self._original_text

        base_url = self._repository_uri + "/" + self.book.get_text_file_dir_path()

        valid_extensions = ("-0.txt", "-8.txt", ".txt")
        if self._repository_uri.startswith("file://"):
            valid_extensions = ("-0.txt", "-8.txt", ".txt", "-0.zip", "-8.zip", ".zip")
        for extension in valid_extensions:
            url = base_url + extension
            try:
                found_url = url_exists(url)
            except: # aleph is not reliable, just use gutenberg directly for now
                url = re.sub(self._repository_uri, "http://www.gutenberg.org/files", url)
                id = self.book.get_book_id_number()
                url = re.sub(self.book.get_text_file_dir_path(), f"{id}/{id}", url)

                found_url = url_exists(url)

            if found_url:
                break


        # TODO: once search does not find audio editions anymore uncomment this:
        # if not found_url:
        #     raise Warning(
        #        "Could not find the text file for {} {}.".format(
        #           book.get_author(),
        #           book.get_title()
        #       )
        #    )
        # TODO: once search does not find audio anymore editions remove this:
        if not found_url:
            return None

        try:
            raw_file_path = download_files(url, self._temporary_dir / self.book.get_text_file_name(), self.book._title)
            if raw_file_path.endswith(".zip"):
                self._original_text = self.unarchive_book(raw_file_path)
                path = pathlib.Path(raw_file_path)
                path.unlink()

            else:
                with open(raw_file_path, "r", encoding="utf8", errors='ignore') as book_text_file:
                    self._original_text = book_text_file.read()
                path = pathlib.Path(raw_file_path)
                path.unlink()

        except Exception as ex:
            raise ex

        return self._original_text

    def get_clean_text(self):
        """
        Return text without header, footer, notes or annotations.

        Parameters
        ----------
        book: dhtk.common.book.Book
            An instance of class Book in dhtk.common.book

        Returns
        -------
        return: str:
        """
        if not self._original_text:
            self.get_original_text()

        if not self._clean_text:
            self._clean()

        return self._clean_text

    def save_original_text_file_to(self, destination):
        """
        Save the original text to a text-file in or at destination.

        Parameters
        ----------
        book: dhtk.common.book.Book
           An instance of class Book in dhtk.common.book
        destination: str
           Path of the destination where the text will be saved.

        Returns
        -------
        return: str
           Path of the saved file.
           """

        filename = self.book.get_text_file_name()
        filename = destination / filename
        if filename.is_file() and filename.stat().st_size == 0:
            return filename

        self.get_original_text()

        if not destination.is_dir():
            destination.mkdir(parents=True, exist_ok=True)

        try:
            with open(filename, "w", encoding='utf8') as file_writer:
                file_writer.write(self._original_text)
        except IOError:
            # LOGGER.warning("File %s could not be created.", filename)
            print("File %s could not be created.", filename)
        return filename

    def save_clean_text_file_to(self, destination):
        """
        Save the clean text to a text-file in or at destination.

        Parameters
        ----------
        book: dhtk.common.book.Book
            An instance of class Book in dhtk.common.book
        destination: str
            Path of the destination where the text will be saved.

        Returns
        -------
        return: str
            Path of the saved file.
        """
        self.get_original_text()

        self.get_clean_text()

        destination = Path(destination)

        if not destination.is_dir():
            destination.mkdir(parents=True, exist_ok=True)

        filename = self.book.get_text_file_name()

        filename = destination / filename
        if not filename.is_file() or filename.stat().st_size == 0:
            with open(filename, "w") as file_writer:
                file_writer.write(self._clean_text)

        return filename

    def _clean(self):
        """
        Remove header, footer, notes and annotations.

        Returns
        -------
        return: str
            Cleaned text.
        """
        # TODO: improve cleaning
        encoded_text = self._original_text
        # normalize the line endings to save us grief later
        encoded_text = encoded_text.replace('\r\n', '\n')
        self._clean_text = self._extract_text(encoded_text)

    @staticmethod
    def _make_re_from_phrase(phrase):
        """
        Make a regular expression that matches a phrase and its surrounding paragraph.

         i.e. that look like:
            ... phrase ....
            more _original_text
            [blank]
            [blank]+

        Parameters
        ----------
        phrase: str:

        Returns
        -------
        return: regular expression object:
            Compiled regex object that matches a phrase and its surrounding paragraph.
        """
        paragraph_text = r'(^.+\w.+\n)*'  # need \S to ensure not just whitespace

        # TODO: check slowdown due to inclusion of '^.*' at start
        tmp = '^.*' + re.escape(phrase) + r'.*\n' + paragraph_text + r'\s+'
        tmp = tmp.replace("\\ ", "(\\s|\\n)*")
        tmp = tmp.replace(":", "(:|\\s|\\n)*")
        return re.compile(tmp, re.I | re.M)  # make it case insensitive

    def _find_max(self, phrase, string):
        """
        Find farthest occurrence of string in phrase.

        Parameters
        ----------
        phrase: str:
            Phrase to be searched in string.
        string: str:
            String to be searched for phrase.

        Returns
        -------
        return: int:
        """
        max_index = 0
        regex = self._make_re_from_phrase(phrase)
        matches = regex.finditer(string)
        for match in matches:
            max_index = max(match.end(), max_index)
        return max_index

    def _find_min(self, phrase, string):
        """
        Find nearest occurrence of string in phrase.

        Parameters
        ----------
        phrase: str:
            Phrase to be searched in string.
        string: str:
            String to be searched for phrase.

        Returns
        -------
        return: int:
        """
        min_index = len(string)
        regex = self._make_re_from_phrase(phrase)
        matches = regex.finditer(string)
        for match in matches:
            min_index = min(match.start(), min_index)
        return min_index

    def _extract_text(self, encoded_text):
        """
        Extract the core _original_text.

        Parameters
        ----------
        encoded_text: str:

        Returns
        -------
        return: str:
            Original text.
        """
        self._notes_end = self._get_notes_end(encoded_text)
        self._header_end = self._get_header_end(encoded_text)
        self._footer_start = self._get_footer_start(encoded_text)

        regex = self._make_re_from_phrase(self.book.get_title())
        title_idx = [match.start() for match in regex.finditer(encoded_text)]
        start_index = next(idx for idx in title_idx if idx > self._header_end)
        if not start_index:
            start_index = self._header_end
            if self._notes_end  > 0:
                start_index = self._notes_end

        return str(encoded_text[start_index: self._footer_start].rstrip())

    def _get_notes_end(self, encoded_text):
        """
        Find the index of the end of the notes.
        Return 0 if no notes.

        Parameters
        ----------
        encoded_text: str
            Text to be searched.

        Returns
        -------
        return: int
        """
        indices = [self._find_min(phrase, encoded_text) for phrase in self.notes_end_phrases]
        index = max(indices)
        return index

    def _get_header_end(self, encoded_text):
        """
        Find the index of the end of the header.

        Parameters
        ----------
        encoded_text: str
            Text to be searched.

        Return
        ------
        return: int
        """
        indices = [self._find_max(phrase, encoded_text) for phrase in self.header_end_phrases]
        return max(indices)

    def _get_footer_start(self, encoded_text):
        """
        Return the index of the beginning of the footer.

        Parameters
        ----------
        encoded_text: str
            Text to be searched.

        Returns
        -------
        return: int
        """
        indices = [self._find_min(phrase, encoded_text) for phrase in self.footer_start_phrases]
        return min(indices)

    def __del__(self):
        try:
            if self._temporary_dir.is_dir():
                shutil.rmtree(self._temporary_dir)
        except NameError:
            pass

    def unarchive_book(self, path, destination=None):
        """

        Parameters
        ----------
        path
            Path of the archive of a book. A Zip file containing a single txt file.
        destination
            Path where the texfile should be extracted.

        Returns
        -------
        book_text: str
            The raw text of the book.
        -------

        """
        title = path.rsplit("/", 1)[1].replace(".zip", "")
        archive = zipfile.ZipFile(path, 'r')

        for txt_file in archive.namelist():
            print(title)
            if txt_file.endswith(".txt"):
                raw_text = archive.read(txt_file)
                break

        detect = chardet.detect(raw_text)

        raw_text = raw_text.decode(detect["encoding"])
        if destination:
            try:
                with open(destination, "w")as out_file:
                    out_file.write(destination)
            except IOError:
                # TODO: fix logger this
                raise IOError("%s could not be written.", destination)

        return raw_text

    def close(self):
        """Remove temporary directory if instance is closed."""
        try:
            if self._temporary_dir.is_dir():
                shutil.rmtree(self._temporary_dir)
        except NameError:
            pass
